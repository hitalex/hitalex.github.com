<?xml version="1.0" encoding="utf-8"?>
  <rss version="2.0"
        xmlns:content="http://purl.org/rss/1.0/modules/content/"
        xmlns:atom="http://www.w3.org/2005/Atom"
  >
  <channel>
    <title>{"name"=>"孔明"}</title>
    <link href="http://localhost:4000/feed/" rel="self" />
    <link href="http://alexkong.net/" />
    <lastBuildDate>2014-07-22T11:47:59+08:00</lastBuildDate>
    <webMaster>kqingchao@gmail.com</webMaster>
    
    <item>
      <title>高斯混合模型和期望最大化算法</title>
      <link href="http://localhost:4000/2014/07/GMM-and-EM/"/>
      <pubDate>2014-07-14T00:00:00+08:00</pubDate>
      <author>{"name"=>"孔明"}</author>
      <guid>http://localhost:4000/2014/07/GMM-and-EM</guid>
      <content:encoded><![CDATA[<h1 id="section">概述</h1>
<p>在这篇博文中，我们将讨论高斯混合模型（Gaussian Mixture Models，GMM）以及它的求解方法–期望最大化（Expectation-Maximization，EM）算法。GMM是经典的无监督聚类模型，它假设数据是从多个高斯分布中得到。我们在GMM的模型求解过程中引入“隐变量”（latent variable）的概念，并基于此使用EM算法求解模型参数。GMM在语音识别技术中有应用。</p>

<h1 id="section-1">求解高斯混合模型：初尝败果</h1>
<p>在线性判别分析（Linear Discriminant Analysis, LDA）中，我们假设每类中的数据服从高斯分布，通过计算两类之间的判别超平面得到分类函数。注意，在线性判别分析中，数据是有类别标签的，也就是属于有监督的分类问题。GMM与线性判别分析模型具有同样的数据生成假设，不同的是，GMM的训练数据中没有类别标签，即为无监督模型。一般地，GMM的定义如下：</p>

<script type="math/tex; mode=display">
p(\mathbf{\mbox{x}}) = \sum_{k=1}^K \pi_k \mathcal{N}(\mathbf{\mbox{x}} | \mathbf{\mu}_k, \mathbf{\Sigma}_k)
</script>

<p>其中，<script type="math/tex">\mathcal{N}</script>表示（多元）高斯分布，<script type="math/tex">K</script>表示混合高斯的个数，<script type="math/tex">\pi_k</script>表示混合参数（mixing coefficient），满足<script type="math/tex">0 \le \pi_k \le 1</script>和<script type="math/tex">\sum_{k=1}^K \pi_k = 1</script>。我们首先尝试使用最大似然方法求解，那么目标就是最大化下式：</p>

<script type="math/tex; mode=display">
\ln p(\mathbf{\mbox{X}}|\mathbf{\pi}, \mathbf{\mu}, \mathbf{\Sigma}) = \sum_{n=1}^{N} \ln \left\{ \sum_{k=1}^K \pi_k \mathcal{N}(\mathbf{\mbox{x}}_n | \mathbf{\mu}_k, \mathbf{\Sigma}_k) \right\}
</script>

<p>如果此时试图使用<a href="http://en.wikipedia.org/wiki/Lagrange_multiplier">拉格朗日乘数法</a>来求解，那么遇到的最大麻烦将是<script type="math/tex">\ln \{ \cdots \}</script>这一部分，导致根本无法继续求解。</p>

<h1 id="section-2">引入隐变量</h1>
<p>接下来，我们将引入“隐变量”。我们假设，对于数据点<script type="math/tex">\mathbf{\mbox{x}}</script>来说存在一个隐变量<script type="math/tex">\mathbf{\mbox{z}}</script>，也就意味着对于每个数据点的取值都存在一个相应的隐变量的取值，但是无法观测得到。隐变量<script type="math/tex">\mathbf{\mbox{z}}</script>的定义如下：<script type="math/tex">\mathbf{\mbox{z}}</script>为<script type="math/tex">K</script>维变量，满足<script type="math/tex">z_k \in \{0, 1\}</script>而且<script type="math/tex">\sum_k z_k = 1</script>，也就意味着隐变量<script type="math/tex">\mathbf{\mbox{z}}</script>中有且仅有一位为1，其他位置都为0。<script type="math/tex">\mathbf{\mbox{z}}</script>和<script type="math/tex">\pi_k</script>的关系如下：</p>

<script type="math/tex; mode=display">
p(z_k = 1) = \pi_k
</script>

<p>那么，</p>

<script type="math/tex; mode=display">
p(\mathbf{\mbox{z}}) = \prod_k^K \pi_k^{z_k}
</script>

<p>注意，这是一个向量的概率密度定义，你可能需要仔细琢磨一下其中的含义。隐变量<script type="math/tex">\mathbf{\mbox{z}}</script>的含义为：如果<script type="math/tex">z_k = 1</script>，那么表示观测值<script type="math/tex">\mathbf{\mbox{x}}</script>就来自第<script type="math/tex">k</script>个聚类（cluster）。基于以上定义，可以得到：</p>

<script type="math/tex; mode=display">
p(\mathbf{\mbox{x}}|z_k = 1) = \mathcal{N}(\mathbf{\mbox{x}} | \mathbf{\mu}_k, \mathbf{\Sigma}_k)
</script>

<p>以及</p>

<script type="math/tex; mode=display">
p(\mathbf{\mbox{x}} | \mathbf{\mbox{z}}) = \prod_{k=1}^K \mathcal{N} (\mathbf{\mbox{x}} | \mathbf{\mu}_k, \mathbf{\Sigma}_k)^{z_k}
</script>

<p>读者可以尝试利用已经得到的<script type="math/tex">p(\mathbf{\mbox{z}})</script>和<script type="math/tex">p(\mathbf{\mbox{x}} \vert \mathbf{\mbox{z}})</script>重新表示<script type="math/tex">p(\mathbf{\mbox{x}})</script>，验证下式：</p>

<script type="math/tex; mode=display">
p(\mathbf{\mbox{x}}) = \sum_{\mathbf{\mbox{z}}} p(\mathbf{\mbox{z}}) p(\mathbf{\mbox{x}} | \mathbf{\mbox{z}}) = \sum_{k=1}^K \pi_k \mathcal{N}(\mathbf{\mbox{x}} | \mathbf{\mu}_k, \mathbf{\Sigma}_k)
</script>

<h1 id="em">EM算法登场</h1>
<p>我们首先给出EM算法的一般步骤，然后将其应用于GMM的参数求解。</p>

<h2 id="em-1">EM算法的一般步骤</h2>
<p>给定观测数据<script type="math/tex">\mathbf{\mbox{X}}</script>，其中第<script type="math/tex">n</script>行<script type="math/tex">\mathbf{\mbox{x}}_n^T</script>表示第<script type="math/tex">n</script>个观测数据，列的个数为数据的维数。正如我们之前所介绍的，每个观测数据都对应一个隐变量的取值–采用<script type="math/tex">\mathbf{\mbox{Z}}</script>表示，<script type="math/tex">\mathbf{\mbox{z}}_n^T</script>表示对应<script type="math/tex">\mathbf{\mbox{x}}_n^T</script>的隐变量取值，经常称<script type="math/tex">\{ \mathbf{\mbox{X,Z}} \}</script>为完整数据（complete data）。在加入隐变量之后，似然函数变为（<script type="math/tex">\mathbf{\theta}</script>表示模型的未知参数集合）：</p>

<script type="math/tex; mode=display">
\ln p(\mathbf{\mbox{X}} | \mathbf{\theta}) = \ln \left\{ \sum_{\mathbf{\mbox{z}}} p(\mathbf{\mbox{X}}, \mathbf{\mbox{Z}} | \mathbf{\theta}) \right\}
</script>

<p>直接使用上式对参数<script type="math/tex">\mathbf{\theta}</script>求导还是会遇到前面所遇到的问题，接下来介绍EM算法如何求解。</p>

<p>假定已经给定了一组模型参数的初始取值<script type="math/tex">\mathbf{\theta}^{\mbox{old}}</script>，我们可以先计算隐变量<script type="math/tex">\mathbf{\mbox{Z}}</script>的后验概率，即<script type="math/tex">p(\mathbf{\mbox{Z}} \vert \mathbf{\mbox{X}}, \mathbf{\theta}^{\mbox{old}})</script>。因为<script type="math/tex">p(\mathbf{\mbox{X}} \vert \mathbf{\theta})</script>的形式较为复杂，我们转而考虑完整数据的似然：<script type="math/tex">p(\mathbf{\mbox{X}}, \mathbf{\mbox{Z}} \vert \mathbf{\theta})</script>。</p>

<p>EM算法的E-step如下，计算：</p>

<script type="math/tex; mode=display">
\mathcal{Q} (\mathbf{\theta}, \mathbf{\theta}^{\mbox{old}}) = \sum_{\mathbf{\mbox{Z}}} p(\mathbf{\mbox{Z}} | \mathbf{\mbox{X}}, \mathbf{\theta}^{\mbox{old}}) \ln p(\mathbf{\mbox{X}}, \mathbf{\mbox{Z}} | \mathbf{\theta})
</script>

<p>对于E-step，有以下几点需要注意：</p>

<ul>
  <li>
    <p><script type="math/tex">\mathcal{Q}</script>本质上是关于变量<script type="math/tex">\mathbf{\mbox{Z}}</script>的期望，即<script type="math/tex">\mathcal{Q} (\mathbf{\theta}, \mathbf{\theta}^{\mbox{old}}) = \mathbb{E}_{\mathbf{\mbox{z}}} [\ln p(\mathbf{\mbox{X}}), \mathbf{\mbox{Z}} \vert \mathbf{\theta} ] </script>，其中<script type="math/tex">\mathbf{\mbox{Z}}</script>的概率密度由<script type="math/tex">p(\mathbf{\mbox{Z}} \vert \mathbf{\mbox{X}}, \mathbf{\theta}^{\mbox{old}})</script>给定（在这里我们假设<script type="math/tex">\mathbf{\mbox{Z}}</script>是离散变量，如果<script type="math/tex">\mathbf{\mbox{Z}}</script>是连续值，那么仅需要将期望中的求和改为积分便可）。</p>
  </li>
  <li>
    <p><script type="math/tex">\mathcal{Q} (\mathbf{\theta}, \mathbf{\theta}^{\mbox{old}})</script>中，<script type="math/tex">\mathbf{\theta}</script>是变量，而<script type="math/tex">\mathbf{\theta}^{\mbox{old}}</script>是已经给定参数值。由于EM是迭代求解算法，这里的<script type="math/tex">\mathbf{\theta}^{\mbox{old}}</script>实际上是上一轮中模型参数的取值。</p>
  </li>
  <li>
    <p>一般来说，模型中的参数不止一个，即<script type="math/tex">\mathbf{\theta}</script>是各个参数构成的向量（此处假设各个参数之间是独立的）。在实际应用中则需要分别计算不同参数的<script type="math/tex">\mathcal{Q} (\mathbf{\theta}_i, \mathbf{\theta}_{\neg i}, \mathbf{\theta}^{\mbox{old}})</script>。</p>
  </li>
</ul>

<p>EM算法的M-step为：</p>

<script type="math/tex; mode=display">
\mathbf{\theta}^{\mbox{new}} = \mbox{argmax}_{\mathbf{\theta}} \mathcal{Q} (\mathbf{\theta}, \mathbf{\theta}^{\mbox{old}})
</script>

<p>对于M-step，有以下几点需要注意：</p>

<ul>
  <li>
    <p>M-step实际上是一个优化问题，所以必须要求<script type="math/tex">\mathcal{Q} (\mathbf{\theta}, \mathbf{\theta}^{\mbox{old}})</script>的形式不能太复杂，也就意味着<script type="math/tex">\mathbf{\mbox{Z}}</script>的后验概率以及<script type="math/tex">\{ \mathbf{\mbox{X}},\mathbf{\mbox{Z}} \}</script>的全概率公式的形式不能太复杂。</p>
  </li>
  <li>
    <p>由于模型参数通常有其他约束，例如GMM中的<script type="math/tex">\pi_k</script>，所以求解优化算法时通常使用拉格朗日乘数法。</p>
  </li>
</ul>

<h2 id="emgmm">将EM算法应用于GMM</h2>
<p>首先，根据<script type="math/tex">p(\mathbf{\mbox{z}})</script>和<script type="math/tex">p(\mathbf{\mbox{x}} \vert \mathbf{\mbox{z}})</script>计算<script type="math/tex">p(\mathbf{\mbox{x,z}})</script>，进而计算完整数据<script type="math/tex">\{\mathbf{\mbox{X,Z}}\}</script>的似然。计算后可得：</p>

<script type="math/tex; mode=display">
p(\mathbf{\mbox{X,Z}} \vert \mathbf{\mu, \Sigma, \pi}) = \prod_{n=1}^N \prod_{k=1}^K \pi_k^{z_{nk}} \mathcal{N}(\mathbf{\mbox{x}}_n \vert \mathbf{\mu_k, \Sigma_k})^{z_{nk}}
</script>

<p>将上式取log后的结果为：</p>

<script type="math/tex; mode=display">
\ln p(\mathbf{\mbox{X,Z}} \vert \mathbf{\mu, \Sigma, \pi}) = \sum_{n=1}^N \sum_{k=1}^K z_{nk} \{ \ln \pi_k + \ln \mathcal{N}(\mathbf{\mbox{x}}_n \vert \mathbf{\mu_k, \Sigma_k}) \}
</script>

<p>根据贝叶斯公式，由<script type="math/tex">p(\mathbf{\mbox{X,Z}} \vert \mathbf{\mu, \Sigma, \pi})</script>可以得到<script type="math/tex">\mathbf{\mbox{Z}}</script>的后验概率（除以 <script type="math/tex">p(\mathbf{\mbox{X}} \vert \mathbf{\mu, \Sigma, \pi})</script>）：</p>

<script type="math/tex; mode=display">
p(\mathbf{\mbox{Z} \vert \mbox{X}}, \mathbf{\mu, \Sigma, \pi}) \propto \prod_{n=1}^N \prod_{k=1}^K [ \pi_k \mathcal{N}(\mathbf{\mbox{x}}_n \vert \mathbf{\mu_k, \Sigma_k})]^{z_{nk}}
</script>

<p>从上式中可以看出，<script type="math/tex">\{ \mathbf{\mbox{z}}_n \}</script>之间是相互独立的。回想EM算法的E-step，接下来我们利用<script type="math/tex">\ln p(\mathbf{\mbox{X,Z}} \vert \mathbf{\mu, \Sigma, \pi})</script>和<script type="math/tex">p(\mathbf{\mbox{Z} \vert \mbox{X}}, \mathbf{\mu, \Sigma, \pi})</script>来计算<script type="math/tex">\mathcal{Q} (\mathbf{\theta}, \mathbf{\theta}^{\mbox{old}})</script>，具体过程如下：</p>

<script type="math/tex; mode=display">% <![CDATA[

\begin{array}{cc}
\mathcal{Q} (\mathbf{\theta}, \mathbf{\theta}^{\mbox{old}})  & =  \sum_{\mathbf{\mbox{Z}}} p(\mathbf{\mbox{Z}} | \mathbf{\mbox{X}}, \mathbf{\theta}^{\mbox{old}}) \ln p(\mathbf{\mbox{X}}, \mathbf{\mbox{Z}} | \mathbf{\theta}) \\
& =  \sum_{\mathbf{\mbox{Z}}} p(\mathbf{\mbox{Z \vert X}}, \mathbf{\mu, \Sigma, \pi}) \left{ \Sigma_{n=1}^N \Sigma_{k=1}^K z_nk \{ \ln pi_k + \ln \mathcal{N}(\mathbf{\mbox{x_n}} \vert \mathbf{\mu}_k, \mathbf{\Sigma}_k) \} \right} \\
& =  \Sigma_{n=1}^N \Sigma_{k=1}^K \Sigma_{z_{nk}} p(\mathbf{\mbox{z}_{nk} \vert \mbox{X}}, \mathbf{\mu, \Sigma, \pi}) z_{nk} \{ \ln \pi_k + \ln \mathcal{N}(\mathbf{\mbox{x}}_n \vert \mathbf{\mu}_k, \mathbf{\Sigma}_k) \} \\
& =  \Sigma_{n=1}^N \Sigma_{k=1}^K \mathbb{E}[z_{nk}] \{ \ln \pi_k + \ln \mathcal{N}(\mathbf{\mbox{x}}_n \vert \mathbf{\mu}_k, \mathbf{\Sigma}_k) \}
\end{array}
 %]]></script>

<p>其中，<script type="math/tex">\mathbb{E}[z_{nk}]</script>的计算如下：</p>

<script type="math/tex; mode=display">
\mathbb{E}[z_{nk}] = \frac{\Sigma_{z_{nk}} z_{nk} [\pi_k \mathcal{N}(\mathbf{\mbox{x}}_n \vert \mathbf{\mu}_k, \mathbf{\Sigma}_k})]^{z_{nk}}}{\Sigma_{z_{nj}}[\pi_j \mathcal{N}(\mathbf{\mbox{x}}_n \vert \mathbf{\mu}_j, \mathbf{\Sigma}_j})]^{z_{nj}}} = \gamma(z_{nk})
</script>

<p>此时，计算<script type="math/tex">\gamma(z_{nk})</script>已经成为EM算法迭代的一个中间变量，稍后关于其他参数的迭代计算都会依赖这个值。另外，计算这个中间变量时使用的是上一轮中的参数，即<script type="math/tex">\theta^{\mbox{old}}</script>。</p>

<p>接下来是EM算法中的M-step：</p>

<script type="math/tex; mode=display">
\mathcal{Q} (\mathbf{\theta}, \mathbf{\theta}^{\mbox{old}}) = \mathbb{E}_{\mathbf{\mbox{z}}} [\ln p(\mathbf{\mbox{X}}, \mathbf{\mbox{Z}} \vert \mathbf{\theta}) ] \\
= \gamma(z_{nk}) \{ \ln \pi_k + \ln \mathcal{N}(\mathbf{\mbox{x}}_n \vert \mathbf{\mu}_k, \mathbf{\Sigma}_k}) \}
</script>

<p>在得到上式后便可以使用拉格朗日乘数法分别对<script type="math/tex">\pi_k, \mathbf{\mu}_k, \mathbf{\Sigma}_k}</script>偏导求解，具体过程略过。<em>强烈</em>建议读者自行推导这个优化过程，这其中涉及到拉格朗日乘数法、多元高斯概率密度函数对均值和协方差矩阵的求导等–你真的可能不了解其中的一些细节，除非你自己推导过n遍。</p>

<p>在经历了较为繁琐的推导过程后，你将发现结果的形式却相对简单。我们定义：<script type="math/tex">N_k = \sum_{n=1}^N\gamma(z_{nk})</script>。其含义可以理解为：平均而言，第<script type="math/tex">k</script>个聚类中所含有的样本的个数。M-step中其他参数的迭代计算方法如下：</p>

<script type="math/tex; mode=display">
\mathbf{\mu}_k^{\mbox{new}} = \frac{1}{N_k} \sum_{n=1}^N \gamma(z_{nk}) \mathbf{\mbox{x}}_n
</script>

<script type="math/tex; mode=display">
\mathbf{\Sigma}_k^{\mbox{new}} = \frac{1}{N_k} \sum_{n=1}^N \gamma(z_{nk}) (\mathbf{\mbox{x}}_n - \mathbf{\mu}_k^{\mbox{new}}) (\mathbf{\mbox{x}}_n - \mathbf{\mu}_k^{\mbox{new}})^T
</script>

<script type="math/tex; mode=display">
\mathbf{\pi}_k^{\mbox{new}} = \frac{N_k}{N}
</script>
]]></content:encoded>
    </item>
    
    <item>
      <title>论文阅读笔记 - 2014.6.21</title>
      <link href="http://localhost:4000/2014/06/paper-reading-notes/"/>
      <pubDate>2014-06-21T00:00:00+08:00</pubDate>
      <author>{"name"=>"孔明"}</author>
      <guid>http://localhost:4000/2014/06/paper-reading-notes</guid>
      <content:encoded><![CDATA[<h1 id="section">引言</h1>
<p>从本周开始，坚持每周至少写一篇论文阅读笔记。要求精读，详细说明论文方法，并分析该篇文章的优点和缺点。如有可能，提出自己的观点。</p>

<p>这篇博文主要讨论两篇文章，第一作者都是Xiangnan He，<a href="http://www.comp.nus.edu.sg/~xiangnan/">这里</a>是他的主页。这两篇文章分别是：“Comment-based Multi-View Clustering of Web 2.0 Items”，发表在WWW 2014上，以及“Predicting the Popularity of Web 2.0 Items Based on User Comments”，发表在SIGIR 2014上。两篇文章都和用户评论相关，正好也是我的主要研究内容。</p>

<h1 id="comment-based-multi-view-clustering-of-web-20-items">Comment-based Multi-View Clustering of Web 2.0 Items</h1>
<p>我们先来分析WWW 2014上的这篇，其核心idea是：用户评论，包括评论内容和参与评论的用户能够辅助对web 2.0 items（以后简称items）的聚类。以上两者，再加上items本身的信息共构成三个信息源，所以本文的工作属于多视图聚类（Multi-view clustering）。为了解决多视图聚类问题，作者使用了非负矩阵分解（Non-negative Matrix Factorization, NMF）技术。</p>

<p>进行非负矩阵分解之前，首先需要准备item-feature矩阵<script type="math/tex">V \in \mathbb{R}^{m \times n}</script>，其中<script type="math/tex">m</script>表示item的个数，<script type="math/tex">n</script>表示特征的个数。对于三个视图来说，即item本身、评论内容和评论用户，前两者使用word count，后者使用0-1特征（如果用户存在记为1，不存在记为0）。为了展示三个视图对于item聚类的有效性，作者分别用三个视图进行聚类（包括对特征进行过滤、转换、降维等），并对比分析了聚类结果。</p>

<p>对于多视图聚类问题，本文应用NMF的思路是：在基本的NMF框架下，添加对多个视图下聚类结果的约束，例如添加约束条件使得多个视图下的聚类结果相差不大。根据以上思路写出优化目标函数：</p>

<script type="math/tex; mode=display">
J = \sum_{s=1}^{n_v} \lambda_s \Vert V^{(s)} - W^{(s)}H^{(s)} \Vert + R, s.t. W^{(s)} \ge 0, H^{(s)} \ge 0
</script>

<p>其中，<script type="math/tex">n_s</script>表示视图的个数，矩阵<script type="math/tex">W^{(s)}</script>和<script type="math/tex">H^{(s)}</script>的大小分别为<script type="math/tex">m \times k</script>和<script type="math/tex">k \times n</script>，<script type="math/tex">R</script>是附加的约束条件。</p>

<h2 id="pair-wise-conmf">Pair-wise CoNMF</h2>
<p>Pair-wise CoNMF要求对于任意两个视图的$W$之间相差不应该太大，所以此时的附加约束为：</p>

<script type="math/tex; mode=display">
R_1 = \sum_{s,t} \lambda_{s,t} \Vert W^{(s)} - W^{(t)}\Vert
</script>

<p>本文详尽地提供了目标函数的优化算法推导，其中主要涉及的技术有：<script type="math/tex">\Vert A \Vert = Tr(A^T A)</script>, <script type="math/tex">Tr(AB) = Tr(BA)</script>, 矩阵求导和Lagrange乘数法。</p>

<h2 id="cluster-wise-conmf">Cluster-wise CoNMF</h2>
<p>第二个思路则是考察<script type="math/tex">W</script>的L2 norm: <script type="math/tex">W^T W</script>。因为<script type="math/tex">W</script>的每列表示一个cluster中每个item的分布，所以<script type="math/tex">W^T W</script>实际上表示每个cluster之间的相似度。基于此，第二种附加约束为：</p>

<script type="math/tex; mode=display">
R_2 = \sum_{s,t} \lambda_{s,t} \Vert W^{(s)T}W^{(s)} - W^{(t)T}W^{(t)}\Vert
</script>

<p>目标函数的优化求解方法同上。</p>

<p><script type="math/tex">W</script>和<script type="math/tex">H</script>的初始化：运行k-means聚类，将其聚类结果作为初始化输入。</p>

<p>总结：这是一篇规矩踏实的好文章，写作清晰，论文调研充分，虽是沿用了前人的算法框架，但是也提出了自己的新约束。对于算法模型，文章详细给出了求解步骤，并解决了一个在实际应用中出现的问题，其他还包括算法初始化输入、时间复杂度分析，以及实现了多个基准工作。总的来说，工作比较完整。</p>

<h1 id="predicting-the-popularity-of-web-20-items-based-on-user-comments">Predicting the Popularity of Web 2.0 Items Based on User Comments</h1>
<p>这篇文章发表在SIGIR 2014上，自然跟搜索有关。其核心思想是：单纯基于内容的相关度分析已经不够，可以借助网络内容（web items）的评论信息来提升搜索准确度，这篇文章基于评论信息，通过预测youtube视频的流行度来对其进行搜索排序。具体的技术方法是建立time-aware bipartite ranking。</p>

<p>首先建立二部图（bipartite graph），其中user和item是其中的两种类型的节点，边表示评论信息。见下图：</p>

<p><img src="/images/bipartite-user-item-structure.png" alt="Bipartite User-Item Structures" /></p>

<p>边上的权重<script type="math/tex">w</script>表示该评论（可能是多个评论，因为一个用户可能多次评论一个item）对该item的流行度的贡献。作者认为时间越近的评论产生的作用越大，所以定义<script type="math/tex">w_{ij}</script>如下：</p>

<script type="math/tex; mode=display">
w_{ij} = \delta^{a(t_0 - t_{ij}) + b}
</script>

<p>其中，<script type="math/tex">t_0</script>是搜索排序的时间，<script type="math/tex">t_{ij}</script>是用户<script type="math/tex">u_i</script>对<script type="math/tex">p_j</script>的评论时间，<script type="math/tex">a, b</script>为常数。</p>

<p>作者对于流行度预测有三个假设（hypotheses），如下：</p>

<ul>
  <li>H1 - Temporal factor：如果一个item有更多的最近发表的评论，那么它的流行度更高。</li>
  <li>H2 - Social influence factor：如果某个用户的影响力越高，那么他评论的item更可能流行。</li>
  <li>H3 - Current popularity factor：如果一个item当前已经积累了很多浏览数，那么该item未来更可能流行。
下面分别将以上三个假设采用正则优化的思路进行数学公式实现。</li>
</ul>

<h2 id="h1h2">对于H1和H2的实现</h2>

<script type="math/tex; mode=display">
R_1(f) = \frac{1}{2} \sum_{j=1}^n \sum_{i=1}^m w_{ij} (\frac{f(p_j)}{\sqrt{d_j^p}} - \frac{f(u_i)}{\sqrt{d_i^u}})^2
</script>

<p>其中，<script type="math/tex">d_j^p</script>和<script type="math/tex">d_i^u</script>分别为item <script type="math/tex">p_j</script>和用户<script type="math/tex">u_i</script>的weighted degree，<script type="math/tex">f(p_j)</script>值较大的item将会在排序中获得更靠前的位置。在上面的正则约束中，如果<script type="math/tex">p_j</script>的weighted degree较大，即该item收到更多的评论，那么<script type="math/tex">f(p_j)</script>的值也较大（其他变量的值不变），即体现了H1；另外，上式中括号中的第二项较大时，第一项也会较大，即归一化后<script type="math/tex">f(u_i)</script>也较大时，也就是用户<script type="math/tex">u_i</script>的影响力较大时，<script type="math/tex">f(p_j)</script>的值也会较大。</p>

<h2 id="h2">对于H2的实现</h2>
<p>根据每个用户的朋友数，计算其初始影响力的取值，记为<script type="math/tex">u_i^0</script>，那么</p>

<script type="math/tex; mode=display">
R_2(f) = \sum_{i=1}^m(f(u_i) - u_i^0)^2
</script>

<h2 id="h3">对于H3的实现</h2>
<p>根据在搜索排序时刻的流行度，定义相对流行度的取值<script type="math/tex">p_j^0</script>，那么</p>

<script type="math/tex; mode=display">
R_3(f) = \sum_{j=1}^n(f(p_j) - p_j^0)^2
</script>

<p>最终，目标函数为：<script type="math/tex">Q(f) = R_1 + \alpha R_2 + \beta R_3</script>。求解方法和上一篇文章的相同：alternating optimization　－－　对于两个变量<script type="math/tex">f(p_j)</script>和<script type="math/tex">f(u_i)</script>，分别固定一个，然后优化求解另外一个。求解的最终结果形式在此不再列出。</p>

<p>这篇文章有几处不太严密的地方，在此提出：</p>

<ul>
  <li>在建立二部图时，作者假设了一个用户只对一个item发表一个评论。</li>
  <li>在进行方法检验时，作者是用3天后的结果进行验证，但是为什么是“3天”却没有讨论。</li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>一些计算机方向的学术会议整理</title>
      <link href="http://localhost:4000/2013/07/related-cs-conference/"/>
      <pubDate>2013-07-16T00:00:00+08:00</pubDate>
      <author>{"name"=>"孔明"}</author>
      <guid>http://localhost:4000/2013/07/related-cs-conference</guid>
      <content:encoded><![CDATA[<p>这篇博文简单列举几个与我的研究方向相关的学术会议。提起我的研究方向，其实我现在都没有一个确切的答案。往大了说，可以定位为“社会计算”，往小了说，我主要（打算）使用数据挖掘和机器学习算法，研究社交网络、行为建模方面的问题，应用偏向安全领域。我偏向于寻找新问题和应用，而不是理论研究。我前段时间刚做了一篇关于豆瓣小组评论的文章（ISI 2013），可以在<a href="http://alexkong.net/publication/">Publication页面</a>查看。</p>

<p>从我最喜欢的会议开始说起。</p>

<ul>
  <li><strong>SIGIR</strong> SIGIR是信息检索领域的顶级会议，但近年来也包含一些社交网络、推荐系统和行为建模的文章。<a href="http://sigir2013.ie/">SIGIR 2013</a>举办地在爱尔兰的Dublin，时间为7月28日。</li>
  <li><strong>WWW</strong> WWW包含的topic就更多更广泛一些，理论上关于互联网的研究都可以投稿，<a href="http://www2013.org/">WWW 2013</a>的CFP参见<a href="http://www2013.org/authors/call-for-papers/">这里</a>。WWW的论文质量还是比较高的，我的一个理想就是在这个会议上发一篇长文。</li>
  <li><strong>WSDM</strong> WSDM的主题主要关于搜索和数据挖掘。会议举办的时间不长，到今年才是第6届，但是文章质量却不低。<a href="https://www.wsdm2013.org">WSDM 2013</a>的举办地在意大利罗马，时间为今年的二月份。</li>
</ul>

<p>以上三个会议都无可争议地属于领域顶级会议，这些会议接收的论文中既包含比较传统的研究问题，也有新问题，偏向于应用，不是纯理论推导。如果对纯的理论推到感兴趣，推荐以下几个会议：<strong>ICML</strong>，<strong>NIPS</strong>和<strong>ICDM</strong>，或许还可以加上<strong>KDD</strong>。这些会议我等只有仰望的份儿。</p>

<p>关于社会网络相关的会议，可以考虑看一下<strong>ICWSM</strong>和<strong>ASONAM</strong>。ICWSM的论文主题集中在社交网络中的问题。ICWSM会议的特点是文章名称都很有意思，问题比较新也比叫多样化，更偏人文科学（social science），而不是计算（computational）。ASONAM是最近才了解的会议，也是关注社交网络。在浏览了去年和今年的论文标题后，感觉ASONAM的论文研究得更深，更偏向与计算。</p>

<p>关于社会计算（social computing）的会议，可以参考<a href="http://www.asesite.org/conferences/socialcom/2013/">International Conference on Social Computing</a>。我只是知道有这个会议，论文似乎没有看过。</p>

<p>其实，关于人工智能的会议论文我也会看，比如<strong>AAAI</strong>和<strong>IJCAI</strong>。AAAI还好，IJCAI的主题都非常偏向于传统的人工智能领域，而且还是两年举办一次。值得高兴的是，<a href="http://ijcai13.org/">IJCAI 2013</a>将在北京举办，时间为8月3号到9号。目测IJCAI今年肯定是盛会级别，有超过去年<a href="http://kdd2012.sigkdd.org/‎">KDD 2012</a>的架势。有兴趣的朋友们可以到时侯来凑热闹，会议的一些tutorial还是不错的。</p>

<p>自然语言处理（NLP）领域的论文看得不是很多，不过也有，例如<strong>ACL</strong>，<strong>EMNLP</strong>以及<strong>COLING</strong>等。这些会议的论文更偏向NLP领域的问题，与我的关系就不是很大了。</p>

<p>最后说一下由我们实验室老师曾大军主办的会议<strong>ISI</strong>（Intelligence and Security Informatics），偏向于安全领域。<a href="http://isiconference2013.org/pgs/">ISI 2013</a>的举办地是西雅图，时间为6月4号到7号。</p>

<p>以上就是我较为熟知的几个学术会议，因为我资历尚浅，肯定会有遗漏，还请各位读者留言告知，感激不尽！同时也希望就学术会议这个话题跟大家讨论！</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>ROC和AUC介绍以及如何计算AUC</title>
      <link href="http://localhost:4000/2013/06/introduction-to-auc-and-roc/"/>
      <pubDate>2013-06-22T00:00:00+08:00</pubDate>
      <author>{"name"=>"孔明"}</author>
      <guid>http://localhost:4000/2013/06/introduction-to-auc-and-roc</guid>
      <content:encoded><![CDATA[<p>ROC（Receiver Operating Characteristic）曲线和AUC常被用来评价一个二值分类器（binary classifier）的优劣，对两者的简单介绍见<a href="http://bubblexc.com/y2011/148/">这里</a>。这篇博文简单介绍ROC和AUC的特点，以及更为深入地，讨论如何作出ROC曲线图以及计算AUC。</p>

<h2 id="roc">ROC曲线</h2>
<p>需要提前说明的是，我们这里只讨论二值分类器。对于分类器，或者说分类算法，评价指标主要有precision，recall，F-score<sup id="fnref:1"><a href="#fn:1" class="footnote">1</a></sup>，以及我们今天要讨论的ROC和AUC。下图是一个ROC曲线的示例<sup id="fnref:2"><a href="#fn:2" class="footnote">2</a></sup>。</p>

<p><img src="/images/Roccurves.png" alt="ROC曲线示例" /></p>

<p>正如我们在这个ROC曲线的示例图中看到的那样，ROC曲线的横坐标为false positive rate（FPR），纵坐标为true positive rate（TPR）。下图中详细说明了FPR和TPR是如何定义的。</p>

<p><img src="/images/fpr-and-tpr.png" alt="FPR和TPR定义" /></p>

<p>接下来我们考虑ROC曲线图中的四个点和一条线。第一个点，(0,1)，即FPR=0, TPR=1，这意味着FN（false negative）=0，并且FP（false positive）=0。Wow，这是一个完美的分类器，它将所有的样本都正确分类。第二个点，(1,0)，即FPR=1，TPR=0，类似地分析可以发现这是一个最糟糕的分类器，因为它成功避开了所有的正确答案。第三个点，(0,0)，即FPR=TPR=0，即FP（false positive）=TP（true positive）=0，可以发现该分类器预测所有的样本都为负样本（negative）。类似的，第四个点（1,1），分类器实际上预测所有的样本都为正样本。经过以上的分析，我们可以断言，ROC曲线越接近左上角，该分类器的性能越好。</p>

<p>下面考虑ROC曲线图中的虚线y=x上的点。这条对角线上的点其实表示的是一个采用随机猜测策略的分类器的结果，例如(0.5,0.5)，表示该分类器随机对于一半的样本猜测其为正样本，另外一半的样本为负样本。</p>

<h2 id="roc-1">如何画ROC曲线</h2>
<p>对于一个特定的分类器和测试数据集，显然只能得到一个分类结果，即一组FPR和TPR结果，而要得到一个曲线，我们实际上需要一系列FPR和TPR的值，这又是如何得到的呢？我们先来看一下<a href="http://en.wikipedia.org/wiki/Receiver_operating_characteristic">Wikipedia</a>上对ROC曲线的定义：</p>

<blockquote>
  <p>In signal detection theory, a receiver operating characteristic (ROC), or simply ROC curve, is a graphical plot which illustrates the performance of a binary classifier system as its discrimination threshold is varied. </p>
</blockquote>

<p>问题在于“as its discrimination threashold is varied”。如何理解这里的“discrimination threashold”呢？我们忽略了分类器的一个重要功能“概率输出”，即表示分类器认为某个样本具有多大的概率属于正样本（或负样本）。通过更深入地了解各个分类器的内部机理，我们总能想办法得到一种概率输出。通常来说，是将一个实数范围通过某个变换映射到(0,1)区间<sup id="fnref:3"><a href="#fn:3" class="footnote">3</a></sup>。</p>

<p>假如我们已经得到了所有样本的概率输出（属于正样本的概率），现在的问题是如何改变“discrimination threashold”？我们根据每个测试样本属于正样本的概率值从大到小排序。下图是一个示例，图中共有20个测试样本，“Class”一栏表示每个测试样本真正的标签（p表示正样本，n表示负样本），“Score”表示每个测试样本属于正样本的概率<sup id="fnref:4"><a href="#fn:4" class="footnote">4</a></sup>。</p>

<p><img src="/images/score-ranking.png" alt="按照概率排序" /></p>

<p>接下来，我们从高到低，依次将“Score”值作为阈值threshold，当测试样本属于正样本的概率大于或等于这个threshold时，我们认为它为正样本，否则为负样本。举例来说，对于图中的第4个样本，其“Score”值为0.6，那么样本1，2，3，4都被认为是正样本，因为它们的“Score”值都大于等于0.6，而其他样本则都认为是负样本。每次选取一个不同的threshold，我们就可以得到一组FPR和TPR，即ROC曲线上的一点。这样一来，我们一共得到了20组FPR和TPR的值，将它们画在ROC曲线的结果如下图：</p>

<p><img src="/images/roc-example.png" alt="ROC曲线举例" /></p>

<p>当我们将threshold设置为1和0时，分别可以得到ROC曲线上的(0,0)和(1,1)两个点。将这些(FPR,TPR)对连接起来，就得到了ROC曲线。当threshold取值越多，ROC曲线越平滑。</p>

<p>其实，我们并不一定要得到每个测试样本是正样本的概率值，只要得到这个分类器对该测试样本的“评分值”即可（评分值并不一定在(0,1)区间）。评分越高，表示分类器越肯定地认为这个测试样本是正样本，而且同时使用各个评分值作为threshold。我认为将评分值转化为概率更易于理解一些。</p>

<h2 id="auc">AUC值的计算</h2>
<p>AUC（Area Under Curve）被定义为ROC曲线下的面积，显然这个面积的数值不会大于1。又由于ROC曲线一般都处于y=x这条直线的上方，所以AUC的取值范围在0.5和1之间。使用AUC值作为评价标准是因为很多时候ROC曲线并不能清晰的说明哪个分类器的效果更好，而作为一个数值，对应AUC更大的分类器效果更好。</p>

<p>在了解了ROC曲线的构造过程后，编写代码实现并不是一件困难的事情。相比自己编写代码，有时候阅读其他人的代码收获更多，当然过程也更痛苦些。在此推荐<a href="http://scikit-learn.org/stable/">scikit-learn</a>中关于<a href="https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/metrics/metrics.py#L479">计算AUC的代码</a>。</p>

<h2 id="auc-1">AUC意味着什么</h2>
<p>那么AUC值的含义是什么呢？根据(Fawcett, 2006)，AUC的值的含义是：
&gt; The AUC value is equivalent to the probability that a randomly chosen positive example is ranked higher than a randomly chosen negative example.</p>

<p>这句话有些绕，我尝试解释一下：首先AUC值是一个概率值，当你随机挑选一个正样本以及一个负样本，当前的分类算法根据计算得到的Score值将这个正样本排在负样本前面的概率就是AUC值。当然，AUC值越大，当前的分类算法越有可能将正样本排在负样本前面，即能够更好的分类。</p>

<h2 id="roc-2">为什么使用ROC曲线</h2>
<p>既然已经这么多评价标准，为什么还要使用ROC和AUC呢？因为ROC曲线有个很好的特性：当测试集中的正负样本的分布变化的时候，ROC曲线能够保持不变。在实际的数据集中经常会出现类不平衡（class imbalance）现象，即负样本比正样本多很多（或者相反），而且测试数据中的正负样本的分布也可能随着时间变化。下图是ROC曲线和Precision-Recall曲线<sup id="fnref:5"><a href="#fn:5" class="footnote">5</a></sup>的对比：</p>

<p><img src="/images/roc-and-precall.png" alt="ROC曲线 vs. Precision-Recall曲线" /></p>

<p>在上图中，(a)和(c)为ROC曲线，(b)和(d)为Precision-Recall曲线。(a)和(b)展示的是分类其在原始测试集（正负样本分布平衡）的结果，(c)和(d)是将测试集中负样本的数量增加到原来的10倍后，分类器的结果。可以明显的看出，ROC曲线基本保持原貌，而Precision-Recall曲线则变化较大。</p>

<p>说明，文中除了第一张图来自Wikipedia外，其他的图都来自论文(Fawcett, 2006)<sup id="fnref:6"><a href="#fn:6" class="footnote">6</a></sup>截图. </p>

<p>引用及其他链接：</p>

<ul>
  <li>维基百科中对ROC的介绍: http://en.wikipedia.org/wiki/Receiver_operating_characteristic</li>
  <li>ROC曲线及AUC评价指标 by 冒泡的崔：http://bubblexc.com/y2011/148/</li>
</ul>
<div class="footnotes">
  <ol>
    <li id="fn:1">
      <p>我避免将precision，recall等评价指标翻译成中文，因为它们可能对应多个中文解释，极易产生混淆。<a href="#fnref:1" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:2">
      <p>图片来源：http://en.wikipedia.org/wiki/File:Roccurves.png<a href="#fnref:2" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:3">
      <p>这种映射不一定都是可靠的，即你不一定真的得到了某个样本是正样本的概率。<a href="#fnref:3" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:4">
      <p>注意这里使用了“Score”，而不是概率，我们暂且可以认为“Score”值就是是正样本的概率。<a href="#fnref:4" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:5">
      <p>Davis, J., &amp; Goadrich, M. (2006, June). The relationship between Precision-Recall and ROC curves. In Proceedings of the 23rd international conference on Machine learning (pp. 233-240). ACM.<a href="#fnref:5" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:6">
      <p>(Fawcett, 2006)，Fawcett, T. (2006). An introduction to ROC analysis. Pattern recognition letters, 27(8), 861-874.<a href="#fnref:6" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]></content:encoded>
    </item>
    
    <item>
      <title>关于中文学术论文的格式问题 -- 我的一些看法</title>
      <link href="http://localhost:4000/2012/10/my-views-on-formatting-issues-of-acdemic-papers-in-chinese/"/>
      <pubDate>2012-10-04T00:00:00+08:00</pubDate>
      <author>{"name"=>"孔明"}</author>
      <guid>http://localhost:4000/2012/10/my-views-on-formatting-issues-of-acdemic-papers-in-chinese</guid>
      <content:encoded><![CDATA[<p>先说一下我为什么会关注这个问题。就在几天前，导师给了我一篇中文论文，让我帮忙评审（review）。拿到论文后，我竟然有些兴奋 – 的确，我的桌子上几乎不看任何中文论文。造成这种局面的原因比较尴尬和复杂，我们改日再讨论。在仔细读完论文后，除去内容不谈，我发现在此篇论文在书写格式方面有很大的问题，比如错误使用标点符号、断句、中英文和公式混排等。这其中有些问题也是我在写本科毕业论文的时候注意到的。</p>

<p>究其原因，可能是大家平时读写英文论文、英文E-mail太多，反而忽视或者忘记了中文书写的规范。下面我就谈一谈出现的问题以及我的看法。</p>

<p>（1）如果是用中文书写，建议统一使用中文标点符号，比如“，”而不是“,”，以及使用“（”而不是“(”。中文标点和英文标点虽然在形状相似，但是中文标点符号占的位置更宽。在这里多说一句，程序中不能使用中文标点，否则编译无法通过，不知有多少人曾经因为这个而抓耳挠腮。</p>

<p>有两个特殊的标点符号要特别提醒一下：1）现在无论是论文还是教科书等出版物，对于句号的使用，我见到更多的是用句点，像这样“.”。这实际上是英文中的句号，而中文的句号是圆圈，像这样“。”。我并不清楚关于句号的书写有什么更为特别的规定，也不明白为什么这个错误如此流行；2）关于括号的使用。我的建议是，除了数学公式中的括号，都应该统一使用中文括号，比如“（”和“）”。如果坚持这个原则，有时候看起来括号占的地方确实有些大，不过如果坚持使用英文的括号，比如“(”和“)”，书写过程中则必须频繁的切换中/英文输入法。</p>

<p>（2）段落缩进。中文的段落前要有两个汉字宽度的空间–相必这个大家都清楚。不过，我现在还没有见到哪个在线的编辑器，比如豆瓣日记、人人网日志发布器支持这个特性，而且默认都是没有缩进。所以如果想要缩进的效果，则必须手动在每个段落前加入空格。问题又来了，我到底需要键入多少个空格（这里说的是英文空格）才能看着像是“两个汉字的宽度”，四个还是六个？还是看心情？</p>

<p>（3）或许还是受英文书写习惯的影响，我审的这篇文章中频繁出现在一个句子后、下一个句子前，加入一个空格。这显然是不必要的。另外，还有一些文章中出现顿号和逗号混用的情况，比如“豆瓣，人人，新浪微博等都是社交网站”，表示列举应该使用顿号“、”。英文中因为没有顿号，所以使用逗号来代替。</p>

<p>（4）中英文混排。有时候要在论文中要提及模型的名称或者英文名字，比如LDA、NLP、David Blei等，这就产生了中英文混排的问题。少量的混排问题还不大，如果全篇都是这样的情况，整个排版看起来会非常糟糕，而你又不可能使用英文全角字母，比如“ＬＤＡ、ＮＬＰ、Ｄａｖｉｄ　Ｂｌｅｉ”。关于这个问题，除了直接写成英文论文，也没有很好的解决办法。另外，由于数学公式也常常包含英文字母，所以也会让这个问题更突出。</p>

<p>（5）再来说说字体和间距问题。一般来说，中文使用宋体，而英文是Times New Roman，而公式则是斜体。特别建议，文中的代码（或伪代码）最好是使用等宽字体，例如Courier和Monospace。还有，如果文字太密集，可以调整行间距，比如在Microsoft Word中，如果使用宋体小四字体，则建议使用1.5倍行距。</p>

<p>（6）避免中英文混用，这种情况多出现于口头表达，比如“By the way，我觉得这个problem还cover的不够，有些detail还没有讨论清楚。”似乎这种说话方式能让人感觉很高端的样子，只是有些装叉的嫌疑。</p>

<p>每个人都希望自己的文字赏心悦目（pleasing to the eyes），我觉得排版和格式则是为达到这个目的付出的第一份努力。如果大家觉得还有其他常见的问题，欢迎补充！</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Appplying Gibbs sampling inference to Naive Bayes classification</title>
      <link href="http://localhost:4000/2012/09/applying-gibbs-sampling-inference-to-naive-bayes-classification/"/>
      <pubDate>2012-09-09T00:00:00+08:00</pubDate>
      <author>{"name"=>"孔明"}</author>
      <guid>http://localhost:4000/2012/09/applying-gibbs-sampling-inference-to-naive-bayes-classification</guid>
      <content:encoded><![CDATA[<p>Naive Bayes（naive的另外一种写法为naïve，见<a href="http://en.wiktionary.org/wiki/na%C3%AFve">这里</a>），即朴素贝叶斯，是一种应用贝叶斯原理的简单分类器，常用于文本分类，它基于这样的假设：每个文档中的单词生成都是独立的（所以它是Naive的），并且并不考虑单词之间的顺序（Bag-Of-Words，BOW模型）。在自然语言处理（Natural Language Processing，NLP）领域中，这样的模型被称为Unigram model，当然还有Bigram，Trigram，甚至n-gram model。在n-gram model（n&gt;1）中，单词与单词之间不再独立，而是有一定的转移概率 <code>\(P(w_2 | w_1)\)</code>。举一个简单的例子，比如“我”字后面出现“们”的概率显然比出现“中”的概率大，而在unigram model中则并不考虑这种概率差异。不过即便有这样简单的假设，Naive Bayes方法依然强大。</p>

<p>这里并不打算介绍Naive Bayes的细节，只是推荐两篇文章：
* <strong>Parameter estimation for text analysis</strong>，这篇文章主要介绍参数估计的方法，循序渐进，从极大似然估计（Maximum likelyhood，ML）、最大后验（Maximum A Posteriori，MAP）再到Bayesian estimation，得到估计参数的分布，最后详细推导了LDA（Latent Dirichlet Allocation）的Gibbs sampling推导。
* <strong>Gibbs sampling for the unitialiated</strong>，这篇文章主要介绍了Gibbs sampling，另外还将Gibbs sampling应用到Naive Bayes模型的推导，分析步骤很详细，值得一读。以下简称Unitialiated。</p>

<p>如果你已经读了至少Gibbs sampling for the unitialiated这篇文章，或者本来理解Gibss sampling，我建议你继续阅读。</p>

<p>我将Naive Bayes应用于文本分类（采用的数据集在<a href="http://web.ist.utl.pt/~acardoso/datasets/">这里</a>），并尝试使用Gibbs sampling推导模型参数，参照Unitialiated这篇文章中的伪代码。</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>论文阅读总结</title>
      <link href="http://localhost:4000/2012/08/paper-reading-summary/"/>
      <pubDate>2012-08-31T00:00:00+08:00</pubDate>
      <author>{"name"=>"孔明"}</author>
      <guid>http://localhost:4000/2012/08/paper-reading-summary</guid>
      <content:encoded><![CDATA[<p>以下列出从8月16号以来直到现在所阅读的论文的总结。</p>

<p><strong>Topic visualization</strong></p>

<p><em>Visualizing Topic Models</em> by Allison J.B. Chaney and David M. Blei（AAAI2012）</p>

<p>这篇文章的主要贡献为建立了一个topic model的<a href="http://www.princeton.edu/~achaney/tmve/wiki100k/browse/topic-presence.html">可视化系统TMVE</a>。训练topic model采用的代码为<a href="http://www.cs.princeton.edu/~blei/">David Blei</a>的<a href="http://www.cs.princeton.edu/~blei/lda-c/index.html">lda-c</a>。系统中分别计算了每个topic在整个系统中所占的比例，每个topic中words的分布，topic和topic之间的相似度，每个文档包含某个topic的多少（比例），文档与文档之间的相似度。</p>

<p><em>Probabilistic Latent Semantic Visualization: Topic Model for Visualizing Documents</em> by Tomoharu Iwata, <em>et al.</em> （WWW2006）</p>

<p>假定一个visualization space（2维或者3维，之后称作“可视空间”），认为topic和document都在可视空间中存在latent coordinates，这样其实是将topic和document放在同一个空间中，然后再利用欧几里德距离计算它们之间的相似度。在文章中，作者为了得到topic和document在可视空间的坐标，参照LDA的文档生成过程，提出了一种文档生成过程，其中topic和document的坐标都服从多元高斯分布，最后用EM算法求解。</p>

<p><strong>Bayesian nonparametircs</strong></p>

<p><em>A tutorial on Bayesian nonparametric models</em> by Samuel J. Gershman and David M. Blei （Journal of Mathematical Psychology 2011）</p>

<p>贝叶斯非参数（Bayesian nonparametircs）方法其实是一种自动模型选择方法，采用Bayes理论，让训练数据来决定模型参数，比如高斯混合模型中cluster的数量。这篇文章主要介绍了高斯混合模型（Gaussian mixture models）、Chinese restaurant process（CRP）以及Indian buffet process（IBP）。问题：目前已经了解了CRP，但还并不了解IBP，对于CRP和Dirichlet process(mixtures) 之间的关系还不明白。</p>

<p><em>The Infinite Gaussian Mixture Model</em> by Carl Edward Rasmussen （NIPS2000）</p>

<p>这篇论文主要讨论的是无穷高斯混合模型，该模型中假设cluster的数量无穷多。CRP和无穷高斯混合模型有一定的联系：在cluster的数目K趋于无穷时，新来的数据点选择cluster的概率值定义非常相似。它们之间具体的联系之后讨论。</p>

<p><em>Markov Chain Sampling Methods for Dirichlet Process Mixture Models</em> by Radford M. Neal</p>

<p>这篇论文主要讨论Dirichlet process mixture model以及Gibbs sampling。</p>

<p><strong>Topic model application</strong></p>

<p><em>TwitterRank: Finding Topic-sensitive Influential Twitters</em> by Jianshu Weng, <em>et al.</em> （WSDM2010）</p>

<p>TwitterRank基于PageRank，但与PageRank不同的是，重新定义了两个节点间的转移概率，而这个概率和两个节点（两个Twitter用户）在某个topic相似度有关。</p>

<p><em>Social-Network Analysis Using Topic Models</em> by Youngchul Cha and Junghoo Cho （SIGIR2012）</p>

<p>这篇论文声称可以很好的解决popular nodes（具有较多的incoming link，即粉丝很多）问题。其中最引人注目的是<em>Edge generative model</em>：将每个follower看作是一个document，每个followed user看作是word，这样对于某个用户document，他所follow的用户就构成了这个文档中的word，其中的隐变量即为topic或者兴趣。</p>

<blockquote>
  <table>
    <tbody>
      <tr>
        <td>We use the same notation with LDA. $z$ denotes a labeling of a followed user $g$ with a topic (interest), or simply a topic, $P(z</td>
        <td>f)$ denotes the multinomial distribution of topics given a follower $f$, and $P(g</td>
        <td>z)$ denotes the multinomial distribution of followed users given a topic. $\alpha$ and $\beta$ are Dirichlet priors, constraining $P(z</td>
        <td>f)$ and $P(g</td>
        <td>z)$, respectively.</td>
      </tr>
    </tbody>
  </table>
</blockquote>

<p><em>Modeling User Posting Behavior on Social Media</em> by Zhiheng Xu, <em>et al.</em>（SIGIR2012）</p>

<p>文章认为Twitter用户的转发行为与以下三个方面有关：
* Breaking news
* posts from social friends
* users’ intrinsic interest
作者扩展了LDA模型，将这三种原因加入到模型中。这篇文章主要参考了另外两篇文章：Modeling General and Specific Aspects of Documents with a Probabilistic Topic Model（NIPS2006）和Cross-Cultural Analyisi of Blogs and Forums with Mixed-Collection Topic Models（EMNLP2009）。</p>

<p><strong>总结</strong></p>

<p>目前看论文存在的问题是：贪多，看论文不仔细，没有能够及时总结论文思想，提取idea。</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Problem oriented, not model oriented -- 阶段总结</title>
      <link href="http://localhost:4000/2012/08/problem-oriented-not-model-oriented/"/>
      <pubDate>2012-08-30T00:00:00+08:00</pubDate>
      <author>{"name"=>"孔明"}</author>
      <guid>http://localhost:4000/2012/08/problem-oriented-not-model-oriented</guid>
      <content:encoded><![CDATA[<p><strong>阶段总结</strong></p>

<p>8月4号回到北京，5号休息了一天，之后的一周（6号到10号）就开始在清华听<a href="http://bigeye.au.tsinghua.edu.cn/DragonStar2012/registration.html">龙星计划</a>，讲课的两位老师分别是余凯和张瞳。余凯目前在百度做多媒体相关的研究，相较于张瞳，他更偏向于工业界的应用（余凯本人也非常幽默），而张瞳则是Rutgers大学教授，Stanford博士毕业，统计学的大牛。对于机器学习这个研究领域来说，5天的暑期课程远远不够，课程期间，余凯主要是介绍了机器学习的一些相关概念，比如<a href="http://deeplearning.net/">deep learning</a>（我之前则从未听说），张瞳则主要介绍了优化算法、统计理论方面的知识。其实细想起来，整个课程的知识性收获并不太多，主要是开拓了自己的眼界，多认识了几个大牛，比如清华的<a href="http://www.ml-thu.net/~jun/">朱军</a>，微软的<a href="http://research.microsoft.com/en-us/people/tyliu/">Tie-Yan Liu</a>，计算所的常虹，香港科大的<a href="http://www.cse.ust.hk/~qyang/">杨强</a>。非常巧合的是，杨强就是随后在国际会议中心举办的KDD（Knowledge Discovery and Data Mining） 2012的主席（General Chair）。</p>

<p>10号中午在清华吃完饭后又跑到计算所听了<a href="http://cs.stanford.edu/people/jure/">Jure Leskovec</a>关于社交网络（Social Network）的讲座，回去查找他的主页的时候又一次被震惊：顶级会议（top-tier conference）的paper一堆堆，还加杂着各种best paper。后来才知道，Jure也在KDD 2012的Summer School中也有讲座。</p>

<p>各路大牛齐聚北京，为的就是第一次在中国召开的数据挖掘方面的顶级会议<a href="http://kdd2012.sigkdd.org/">KDD2012</a>。从周日开始，我又开始出现在国际会议中心里，听KDD的报告。</p>

<p>KDD不愧为“盛会”，今年参加会议的人大约在1000人以上。这次我也是开足了眼界，见到了很多书中和paper中的大牛，简单罗列几个：孙茂松、Jiawei Han、 余凯、杨强、周志华、唐洁、<a href="http://www.cs.berkeley.edu/~jordan/">Michael Jordan</a>、Michael Kearns、李彦宏、Tie-yan Liu、林智仁、Xiaojin Zhu。这次的KDD和<a href="http://www.sigir.org/sigir2012/">SIGIR2012</a>会议时间上几乎完全重叠，否则还能见到更多的大牛。在这些大牛中给我留下最深刻印象的是林智仁，他在Industry Practice Expo中做了一个报告：<a href="http://kdd2012.sigkdd.org/indexpo.shtml#lin">Experiences and Lessons in Developing Industry-Strength Machine Learning and Data Mining Software</a>，主要介绍了他们开发LIBSVM的经历。林教授非常和蔼、幽默，就像个小孩子一般，让人感觉很亲近，整个报告的气氛也非常轻松。</p>

<p>从KDD回来，就开始看论文。经过龙星课程和KDD2012的连番轰炸，我开始真正认识到学术圈子（research community），开始关注一些大牛，开始想着如何才能发高质量的论文。这其中也要感谢杨逍的帮忙，整个KDD期间，我都在跟他讨论、请教。我也必须感到庆幸，这些经历都正好发生在我即将开始真正的实验室学术生活的“前一天”。</p>

<p><strong>Problem oriented, not model oriented</strong></p>

<p>我最近一直也在寻找自己的研究方向，自己虽然有些模糊的想法和方向，但还是不够清晰，也不够坚定。从去年看论文开始，一直到现在，我一直都专注于topic model的学习，LDA以及模型求解，再到前几天的模型的应用，我发现我不知不觉到了这样一个误区：先想一个问题，然后再考虑如何用topic model去解决。这不是典型的“有个锤子，就认为满世界都是钉子”思路么？要解决的是实际或者研究问题，模型、方法都只是手段而已。总的来说就是太依赖于某个算法、模型，而忽略了自己要解决的问题，这个问题如此严峻，以至于和我最初的“以问题为导向”（Problem oriented）的研究思路相违背。</p>

<p><strong>Future posts</strong></p>

<p>现在我心里还有几篇博文在“孕育”，写下来防止未来自己不认帐:
* 近几天所看的论文的总结，无论如何都要停下来回顾一下自己看的文章，消化一下。
* From dimension reduction to LDA，关于LSA、PLSA和LDA
* Gibbs sampling，以及其C语言实现
* Bayesian non-parametircs
* 读 <em>Unix编程的艺术</em> 有感</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>如何判断链表中是否存在环路</title>
      <link href="http://localhost:4000/2012/08/whether-there-is-a-loop-in-a-link/"/>
      <pubDate>2012-08-25T00:00:00+08:00</pubDate>
      <author>{"name"=>"孔明"}</author>
      <guid>http://localhost:4000/2012/08/whether-there-is-a-loop-in-a-link</guid>
      <content:encoded><![CDATA[<p>在实习面试中，这个问题出现的频度很高，我在这里总结一下。</p>

<p>方法一，在链表中增加一个域visited，都初始化为0，表示此节点都未被访问。从链表的头部开始走，每走过一个链表就标记visited为1，如果要访问的下一个节点的visited域为1，那么证明链表中有环。</p>

<p>方法二，先考虑另外一个问题：在未知链表长度（长度为奇数）的情况下，如何找到链表中间的节点？可以这么办，设置两个指针p和q，初始时都指向链表的头结点。然后沿着链表，p走一步而q走两步，这样当q正好到达链表的尾节点的时候，p应该在链表的中间节点。</p>

<p>如何判断链表中有环也可以用这种思路，还是设置p和q两个指针，沿着链表走，p走一步而q走两步。如果链表中有环，则p和q会在某个时间相遇。我们来分析一下，在两个指针进入环路之前，肯定不会相遇，那么如果两个指针相遇，则一定是它们都在这个链表的环路之中。假设此时p点刚刚进入到链表中的环中，q在环中的某一个位置，如图所示。</p>

<p><img src="/images/loop-in-link.png" alt="如何判断链表中是否存在环路" /></p>

<p>设t时间后，p和q在环中的某一点相遇，初始时p和q相隔k个节点（0&lt;=k&lt;=n-1，其中n为环中的节点数，在这里为5；图中p和q相隔3个节点，而不是2个：因为假如q不动，p需要经过3步移动才可以和q重合），那么可得：t(mod n) = k + 2t(mod n)，其中t(mod n)代表t除以n所得到的余数，t为正整数。那么显然，设m为正整数，t = mn - k，所以满足要求的最小的k为2（m = 1的时候）。这也就说明了，如果链表中有环，那么p和q在某个时刻一定相遇。</p>

<p>而p和q相遇，是否能说明链表有环呢？答案是肯定的，考虑其逆反命题，如果链表没有环，则p和q则永远不可能相遇。进一步说明了，在这种实验设置之下，p和q相遇是链表有环的充分必要条件。</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>The Great Donald E. Knuth</title>
      <link href="http://localhost:4000/2012/08/the-great-Donald-Knuth/"/>
      <pubDate>2012-08-25T00:00:00+08:00</pubDate>
      <author>{"name"=>"孔明"}</author>
      <guid>http://localhost:4000/2012/08/the-great-Donald-Knuth</guid>
      <content:encoded><![CDATA[<p><img src="/images/Donald-Knuth.jpg" alt="Donald Knuth\[1\]" title="Donald Knuth" /></p>

<p>Note: This is a 5-minute speech script given on my English class.</p>

<p>Good morning, everybody! I am XXX, and you can call me Alex. I’m very honored to introduce you today one of the most respected and fruitful scholars in computer science: <a href="http://en.wikipedia.org/wiki/Donald_Knuth" title="Donald E. Knuth">Donald E. Knuth</a>. Interestingly, he also has a Chinese name: 高德纳.</p>

<p>Knuth was born on January 10, 1938 in Milwaukee, Wisconsin. He was studying physics at Case Institute of Technology and then switched to mathematics. In 1960, he received his Bachelor of Science degree and at the same time received his Master of Science degree because of his excellent work. After 3 years, in 1963, he graduated from California Institute of Technology with a Ph.D degree in mathematics and began to work there as an associate professor.Now he has retired from Stanford University and concentrated on his 7-volumn book: The Art of Computer Programming, known as TAOCP, which I will talk about later on.</p>

<p>Knuth is considered the “father of algorithm analysis”. You all know what an algorithm means, do you? An algorithm is basically a way of doing a certain kind of things; in computer science, it means, taking the advantage of the speed of CPU, how your computer code or software solves problems, which will take a man much more time to do it. Knuth had received so many awards: John von Neumann Medal and Harvey Prize in 1995 and Kyoto Prize in 1996, and the “NuoBeiEr prize in computing”- Turing award in 1974 at the age of 36, for his contributions to the analysis of algorithms and the design of programming languages. </p>

<p>His Turing award was particularly for his life-long project: TAOCP – the 7 volume book which I have just mentioned. In fact, at the time he received the award, he had just finished the first 3 volumes. Volume 4 has just come out and the rest are in preparation. TAOCP is such a great serial book and soon became the “Shengjing” for computer programmers worldwide. Bill Gates once said, “If you think you’re a really good programmer… read (Knuth’s) Art of Computer Programming… You should definitely send me a résumé if you can read the whole thing.” Knuth is even more ambitious: he wanted his book to be something like Newton’s The Mathematical Principle of Natural Philosophy. </p>

<p>Not only does Knuth have so much theoretical achievements, he is also one of the best programmers. After he published his first 3 volumes of TAOCP, he thought his printed books look very bad. Then he decided to study typesetting and font. Eventually he developed his own computer typesetting system Tex which has become the best known typesetting system so far. One thing to add, Tex is open-source, which means everybody can use it free of charge or improve it at one’s own will.</p>

<p>Apart from writing the great serial TAOCP books and several public speeches a year, now he spends most of his time with his family. When asked about his unfinished masterpiece, he said:”The journey is more important than the destination—that’s part of life.” Then he added, “If I had been good at making estimates of how long something was going to take, I never would have started”.</p>

<p>[1] Image source: http://alumni.stanford.edu/get/page/magazine/article/?article_id=33888</p>
]]></content:encoded>
    </item>
    
  </channel>
</rss>
